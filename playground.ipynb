{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'cnn_lstm' # Options: 'cnn', 'lstm', 'cnn_lstm', 'random_forest', 'gradient_boosting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:29:51,348\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-17 19:29:51,519\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (76, 502, 9)\n",
      "X_test shape: (20, 502, 9)\n",
      "y_train shape: 76\n",
      "y_test shape: 20\n",
      "Optimizing hyperparameters for cnn_lstm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:29:55,577\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "2023-11-17 19:29:56,794\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2023-11-17 19:29:56,796\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-17 19:34:01</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:04.17        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.6/63.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=0 total_brackets=2<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=3, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>Logical resource usage: 1.0/16 CPUs, 0/1 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  conv_units</th><th>dense_units  </th><th style=\"text-align: right;\">  learning_rate</th><th>lstm_units  </th><th>model_type  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mean_squared_error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_999a6_00000</td><td>TERMINATED</td><td>127.0.0.1:31672</td><td style=\"text-align: right;\">          64</td><td>[50]         </td><td style=\"text-align: right;\">         0.1   </td><td>[128, 64]   </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        100.838 </td><td style=\"text-align: right;\">             151.953</td></tr>\n",
       "<tr><td>lambda_999a6_00001</td><td>TERMINATED</td><td>127.0.0.1:23624</td><td style=\"text-align: right;\">          64</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.0001</td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        110.787 </td><td style=\"text-align: right;\">             226.859</td></tr>\n",
       "<tr><td>lambda_999a6_00002</td><td>TERMINATED</td><td>127.0.0.1:10908</td><td style=\"text-align: right;\">          32</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.1   </td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.5536</td><td style=\"text-align: right;\">             196.811</td></tr>\n",
       "<tr><td>lambda_999a6_00003</td><td>TERMINATED</td><td>127.0.0.1:14788</td><td style=\"text-align: right;\">          32</td><td>[50]         </td><td style=\"text-align: right;\">         0.0001</td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        111.331 </td><td style=\"text-align: right;\">             225.481</td></tr>\n",
       "<tr><td>lambda_999a6_00004</td><td>TERMINATED</td><td>127.0.0.1:13268</td><td style=\"text-align: right;\">          64</td><td>[50]         </td><td style=\"text-align: right;\">         0.0001</td><td>[128, 64]   </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        237.09  </td><td style=\"text-align: right;\">             208.864</td></tr>\n",
       "<tr><td>lambda_999a6_00005</td><td>TERMINATED</td><td>127.0.0.1:18480</td><td style=\"text-align: right;\">          32</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.1   </td><td>[128, 64]   </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         97.6181</td><td style=\"text-align: right;\">             174.076</td></tr>\n",
       "<tr><td>lambda_999a6_00006</td><td>TERMINATED</td><td>127.0.0.1:17720</td><td style=\"text-align: right;\">          64</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.1   </td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         65.3796</td><td style=\"text-align: right;\">             171.874</td></tr>\n",
       "<tr><td>lambda_999a6_00007</td><td>TERMINATED</td><td>127.0.0.1:12444</td><td style=\"text-align: right;\">          32</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.001 </td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        112.381 </td><td style=\"text-align: right;\">             192.207</td></tr>\n",
       "<tr><td>lambda_999a6_00008</td><td>TERMINATED</td><td>127.0.0.1:17500</td><td style=\"text-align: right;\">          32</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.0001</td><td>[128, 64]   </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        148.745 </td><td style=\"text-align: right;\">             227.693</td></tr>\n",
       "<tr><td>lambda_999a6_00009</td><td>TERMINATED</td><td>127.0.0.1:31736</td><td style=\"text-align: right;\">          32</td><td>[100, 50]    </td><td style=\"text-align: right;\">         0.01  </td><td>[64]        </td><td>cnn_lstm    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         93.3603</td><td style=\"text-align: right;\">             150.737</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2023-11-17 19:30:03.883062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(<lambda> pid=17720)\u001b[0m 2023-11-17 19:30:03.932476: I t\n",
      "\u001b[36m(<lambda> pid=17720)\u001b[0m ensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 1/1000\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/2 [==============>...............] - ETA: 2s - loss: 275.4267\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 263.2615\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 3s 707ms/step - loss: 263.2615 - val_loss: 101.2582\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 105ms/step - loss: 262.6677 - val_loss: 101.1526\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 8/1000\u001b[32m [repeated 39x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - 1s 830ms/step\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 345.9140\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 187.4147\u001b[32m [repeated 72x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 139ms/step - loss: 251.8619 - val_loss: 94.1222\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 4/1000\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - 1s 812ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 393.6259\u001b[32m [repeated 67x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 260.8749\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 166ms/step - loss: 258.6859 - val_loss: 97.9397\u001b[32m [repeated 67x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m Epoch 56/1000\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - 4s 4s/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 141x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 108.9766\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 255.6754\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 2/2 [==============================] - 12s 1s/step - loss: 208.5462 - val_loss: 308.5508\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 11/1000\u001b[32m [repeated 66x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - 1s 963ms/step\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 130x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 291.2618\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 204.2005\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 2/2 [==============================] - 0s 118ms/step - loss: 193.4759 - val_loss: 301.3385\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 36/1000\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/1 [==============================] - 1s 737ms/step\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 113x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 255.3222\u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 201.8923\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - 2s 2s/step\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 13s 2s/step - loss: 208.4641 - val_loss: 305.6962\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 60/1000\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 179x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 264.1979\u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 198.0751\u001b[32m [repeated 76x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 1/1 [==============================] - 1s 1s/step\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - 0s 148ms/step - loss: 198.2193 - val_loss: 297.6102\u001b[32m [repeated 78x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 83/1000\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 88x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 127.8856\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 196.7109\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - 1s 855ms/step\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - 0s 114ms/step - loss: 195.9357 - val_loss: 292.2517\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 108/1000\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 160x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 143.6802\u001b[32m [repeated 71x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 168.7307\u001b[32m [repeated 70x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/1 [==============================] - 1s 640ms/step\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 129ms/step - loss: 167.3246 - val_loss: 455.7518\u001b[32m [repeated 69x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 21/1000\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 112x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 109.8527\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 158.9392\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - 2s 2s/step\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 1s 363ms/step - loss: 205.1435 - val_loss: 305.4198\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m Epoch 2/1000\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 109x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 123.3172\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 254.3226\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 1s 434ms/step - loss: 199.8962 - val_loss: 305.1667\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 19/1000\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 113.3495\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 203.4493\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - 5s 5s/step\n",
      "\u001b[36m(<lambda> pid=17720)\u001b[0m 2/2 [==============================] - 0s 160ms/step - loss: 216.6247 - val_loss: 61.4341\u001b[32m [repeated 64x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th style=\"text-align: right;\">  mean_squared_error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_999a6_00000</td><td style=\"text-align: right;\">             151.953</td></tr>\n",
       "<tr><td>lambda_999a6_00001</td><td style=\"text-align: right;\">             226.859</td></tr>\n",
       "<tr><td>lambda_999a6_00002</td><td style=\"text-align: right;\">             196.811</td></tr>\n",
       "<tr><td>lambda_999a6_00003</td><td style=\"text-align: right;\">             225.481</td></tr>\n",
       "<tr><td>lambda_999a6_00004</td><td style=\"text-align: right;\">             208.864</td></tr>\n",
       "<tr><td>lambda_999a6_00005</td><td style=\"text-align: right;\">             174.076</td></tr>\n",
       "<tr><td>lambda_999a6_00006</td><td style=\"text-align: right;\">             171.874</td></tr>\n",
       "<tr><td>lambda_999a6_00007</td><td style=\"text-align: right;\">             192.207</td></tr>\n",
       "<tr><td>lambda_999a6_00008</td><td style=\"text-align: right;\">             227.693</td></tr>\n",
       "<tr><td>lambda_999a6_00009</td><td style=\"text-align: right;\">             150.737</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=10908)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019A97ECB1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m 2023-11-17 19:30:03.998468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=10908)\u001b[0m To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 1/1000\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m \u001b[32m [repeated 93x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 203.9954\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 245.0571\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/1 [==============================] - 1s 527ms/step\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 349ms/step - loss: 168.2997 - val_loss: 451.2636\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m Epoch 16/1000\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 99x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 230.8603\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 251.9813\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17720)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=17720)\u001b[0m 1/1 [==============================] - 1s 690ms/step\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - 1s 775ms/step\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 334ms/step - loss: 167.9351 - val_loss: 448.4845\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 20/1000\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 110x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 56.1021\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 244.1236\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - 1s 723ms/step\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 161ms/step - loss: 242.3878 - val_loss: 105.9706\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 2/1000\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 215.6069\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 231.6399\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 125ms/step - loss: 231.1598 - val_loss: 94.2568\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - 5s 5s/step\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 61/1000\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 121x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 238.2276\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 169.3978\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 195ms/step - loss: 241.8883 - val_loss: 155.9776\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/1 [==============================] - 1s 621ms/step\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m Epoch 10/1000\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 105x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 247.5706\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 184.6419\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 191ms/step - loss: 240.4473 - val_loss: 153.2185\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 6/1000\u001b[32m [repeated 46x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=31736)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FEE5104A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=31736)\u001b[0m 1/1 [==============================] - 1s 781ms/step\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 140.1517\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 245.0264\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 159ms/step - loss: 237.2372 - val_loss: 149.7262\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 10/1000\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=18480)\u001b[0m 1/1 [==============================] - 2s 2s/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 134.1224\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 241.5763\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - 0s 151ms/step - loss: 230.8823 - val_loss: 137.3481\u001b[32m [repeated 59x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=31672)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023022870A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=12444)\u001b[0m Epoch 47/1000\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=31672)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=31672)\u001b[0m 1/1 [==============================] - 2s 2s/step\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m \u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 121.1336\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=12444)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 221.1699\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 230ms/step - loss: 238.8822 - val_loss: 144.9504\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m Epoch 39/1000\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m \u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=23624)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 86.9322\u001b[32m [repeated 53x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 237.9345\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - 1s 1s/step\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m 2/2 [==============================] - 0s 195ms/step - loss: 235.8677 - val_loss: 143.5829\u001b[32m [repeated 55x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=23624)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025C58DD9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[36m(<lambda> pid=14788)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3AA457B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 5/1000\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 3s - loss: 124.3155\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 245.0826\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/1 [==============================] - ETA: 0s\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/1 [==============================] - 1s 798ms/step\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 4s 922ms/step - loss: 245.0826 - val_loss: 160.3505\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 3/1000\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 387.8583\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 244.0962\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 657ms/step - loss: 243.3300 - val_loss: 159.1933\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 11/1000\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 120.5656\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 241.5358\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 0s 243ms/step - loss: 242.8511 - val_loss: 158.6190\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 24/1000\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 136.4320\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 241.5699\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 0s 265ms/step - loss: 241.4785 - val_loss: 156.9978\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 35/1000\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 183.0749\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 241.2125\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 0s 257ms/step - loss: 241.6495 - val_loss: 155.5034\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 47/1000\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 100.0855\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 239.8573\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - 0s 262ms/step - loss: 240.1179 - val_loss: 154.4131\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m Epoch 59/1000\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m \u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 384.8427\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 239.3062\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 642ms/step - loss: 242.3210 - val_loss: 150.8851\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 33/1000\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=17500)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020E9CE20040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=17500)\u001b[0m 1/1 [==============================] - 1s 653ms/step\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 341.2034\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 239.2818\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 530ms/step - loss: 240.1741 - val_loss: 148.0835\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 38/1000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 111.4631\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 240.2206\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 531ms/step - loss: 239.8853 - val_loss: 145.0691\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 44/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 355.6152\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.7903\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 561ms/step - loss: 238.7903 - val_loss: 142.0964\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 50/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 277.4973\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 239.9517\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 551ms/step - loss: 239.9517 - val_loss: 138.6948\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 56/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 205.4861\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.7124\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 527ms/step - loss: 238.7124 - val_loss: 134.7623\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 62/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 369.9598\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.3811\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 541ms/step - loss: 238.3811 - val_loss: 130.6063\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 68/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 338.3639\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.5287\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 534ms/step - loss: 238.5287 - val_loss: 126.3964\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 73/1000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 82.7310\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.6569\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 507ms/step - loss: 238.6569 - val_loss: 121.8801\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 79/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 211.9174\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 236.9260\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 515ms/step - loss: 236.9260 - val_loss: 116.8141\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 85/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 375.9843\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 237.4079\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 526ms/step - loss: 237.4079 - val_loss: 109.9473\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 91/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 130.2526\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.7390\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 543ms/step - loss: 238.7390 - val_loss: 105.0032\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 97/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 377.1384\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 237.3363\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 522ms/step - loss: 237.3363 - val_loss: 99.0968\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 104/1000\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 95.9921\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 236.6129\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 514ms/step - loss: 236.6129 - val_loss: 96.1899\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 110/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 269.9683\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.0544\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 524ms/step - loss: 238.0544 - val_loss: 88.3166\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 115/1000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 212.0933\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 237.1503\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 529ms/step - loss: 237.1503 - val_loss: 82.3623\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 121/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 158.4186\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 238.7953\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 509ms/step - loss: 238.7953 - val_loss: 78.1190\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 128/1000\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m \u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/2 [==============>...............] - ETA: 0s - loss: 262.0684\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - ETA: 0s - loss: 237.1932\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 2/2 [==============================] - 1s 511ms/step - loss: 237.1932 - val_loss: 71.1919\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m Epoch 134/1000\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:34:01,016\tINFO tune.py:1047 -- Total run time: 244.22 seconds (244.16 seconds for the tuning loop).\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D73065EEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration for cnn_lstm: {'model_type': 'cnn_lstm', 'learning_rate': 0.01, 'conv_units': 32, 'lstm_units': [64], 'dense_units': [100, 50]}\n",
      "{'model_type': 'cnn_lstm', 'learning_rate': 0.01, 'conv_units': 32, 'lstm_units': [64], 'dense_units': [100, 50]}\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - ETA: 0s\n",
      "\u001b[36m(<lambda> pid=13268)\u001b[0m 1/1 [==============================] - 0s 429ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'numpy.ndarray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bianc\\Documents\\GitHub\\predict-compression\\playground.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bianc/Documents/GitHub/predict-compression/playground.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest configuration for \u001b[39m\u001b[39m{\u001b[39;00mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mbest_config\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bianc/Documents/GitHub/predict-compression/playground.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(best_models[model_type])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bianc/Documents/GitHub/predict-compression/playground.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     update_best_configuration(model_type, best_config, best_scores)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bianc/Documents/GitHub/predict-compression/playground.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     config \u001b[39m=\u001b[39m best_config\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bianc/Documents/GitHub/predict-compression/playground.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bianc\\Documents\\GitHub\\predict-compression\\utils.py:17\u001b[0m, in \u001b[0;36mupdate_best_configuration\u001b[1;34m(model_type, best_config, best_scores, file_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m             existing_model, existing_config, existing_mse \u001b[39m=\u001b[39m row\n\u001b[0;32m     16\u001b[0m             existing_data[existing_model] \u001b[39m=\u001b[39m (existing_config, \u001b[39mfloat\u001b[39m(existing_mse))\n\u001b[1;32m---> 17\u001b[0m             \u001b[39mif\u001b[39;00m existing_model \u001b[39m==\u001b[39m model_type \u001b[39mand\u001b[39;00m best_scores[model_type] \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m existing_mse:\n\u001b[0;32m     18\u001b[0m                 should_update \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'numpy.ndarray' and 'str'"
     ]
    }
   ],
   "source": [
    "from prepare_data import split_patient_samples, preprocess_data\n",
    "from parameter_tuning import optimize_hyperparameters\n",
    "from confidence_interval import bootstrap_confidence_interval\n",
    "from train_model import train_model\n",
    "from load_and_save_model import save_model\n",
    "from mse_with_constant_prediction import calculate_baseline_mse\n",
    "from utils import update_best_configuration, load_best_configuration\n",
    "\n",
    "# Load the dataset\n",
    "data_splits = split_patient_samples()\n",
    "X_train, X_test, y_train, y_test = preprocess_data(data_splits, model_type)\n",
    "\n",
    "optimize_params = True # Add to args\n",
    "\n",
    "if optimize_params:\n",
    "    print(f'Optimizing hyperparameters for {model_type}...')\n",
    "    best_scores, best_models = optimize_hyperparameters(X_train, y_train, model_type)\n",
    "    config = best_models[model_type]\n",
    "    print(f'Best configuration for {model_type}: {config}')\n",
    "    update_best_configuration(model_type, config, best_scores)\n",
    "else:\n",
    "    print(f'Loading best configuration for model {model_type} from file...')\n",
    "    config = load_best_configuration(model_type)\n",
    "\n",
    "# Fit best model on entire training data\n",
    "model = train_model(config, X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_model(model, model_type)\n",
    "\n",
    "# # Evaluate model on test data (MSE)\n",
    "# mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# # Bootstrap confidence interval to MSE\n",
    "# mse_ci = bootstrap_confidence_interval(model, X_test, y_test)\n",
    "\n",
    "# # Print the baseline MSE, MSE and MSE confidence interval\n",
    "# baseline_mse = calculate_baseline_mse(y_train, y_test)\n",
    "# print(f\"Baseline MSE (predicting mean): {baseline_mse}\")\n",
    "# print(f'MSE: {mse}')\n",
    "# print(f'MSE confidence interval: {mse_ci}')\n",
    "\n",
    "# # Save the results to a CSV file\n",
    "# with open('results/mse_with_confidence_interval.csv', 'a') as f:\n",
    "#     f.write(f'{model_type},{mse},{mse_ci}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
